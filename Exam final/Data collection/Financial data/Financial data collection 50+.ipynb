{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "969f4761-97d0-4044-867b-dcea5ad27e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import nasdaqdatalink\n",
    "import json\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "import tqdm\n",
    "from eodhd import APIClient\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "82d0562c-ee51-4b6c-9b1f-93b36419db6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api = \"64d77f6d3a60a5.24835840\" #API key\n",
    "eod_path = Path.cwd()/\"Eod\" #path to create folder where end of day stock prices will be stored\n",
    "fundamentals_path = Path.cwd()/\"Fundamentals\"\n",
    "SingleStock_data = Path.cwd()/\"SingleStock_data\"\n",
    "Path.mkdir(eod_path, exist_ok=True)\n",
    "Path.mkdir(fundamentals_path, exist_ok = True)\n",
    "Path.mkdir(SingleStock_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff22e5f-7449-4209-8f84-d1cc526929f9",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5da3d15-4111-4181-8eb9-20a65d31cf82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_json(response):\n",
    "    \"\"\"\n",
    "    Converts a json format variable to a pandasdataframe.\n",
    "    \n",
    "    Args: Response from API call\n",
    "    \n",
    "    returns: pandas dataframe\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(response.json()['values'])\n",
    "    #df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def stock_eod(ticker):\n",
    "    \"\"\"\n",
    "    Get stock data End of Day prices.\n",
    "    \n",
    "    Args(str): ticker name of the stock\n",
    "    \n",
    "    Returns a pandas dataframe outer-merged on 'datetime' \n",
    "    \"\"\"\n",
    "    \n",
    "    ###MAKE API CLALL###\n",
    "    Timeseries = requests.get(f'https://eodhistoricaldata.com/api/eod/{ticker}.US?order=d&from=2022-05-31&to=2023-06-03&period=d&&api_token={api}&fmt=json')\n",
    "    \n",
    "    ### convert json files to pandas dataframes\n",
    "    timeseries_df = pd.DataFrame(Timeseries.json())\n",
    "    timeseries_df[\"date\"] = pd.to_datetime(timeseries_df[\"date\"])  #change date format to datetime\n",
    "    \n",
    "    stock_df = timeseries_df\n",
    "    \n",
    "    return stock_df\n",
    "\n",
    "def stock_fundamental(ticker):\n",
    "    \n",
    "    \"\"\"\n",
    "    Collect fundamentals for a stock given its ticker\n",
    "    \n",
    "    Args(str): ticker\n",
    "    \n",
    "    Returns a pandas dataframe with fundamentals data\n",
    "    \"\"\"\n",
    "    \n",
    "    #Get all fundamental data for a given ticker \n",
    "    url = f'https://eodhistoricaldata.com/api/fundamentals/{ticker}.US?api_token={api}&order=d&filter=outstandingShares::quarterly,Earnings::History'\n",
    "    resp = requests.get(url) #make request\n",
    "    json = resp.json() #convert to json\n",
    "    \n",
    "    #get outstandingShares data and convert to dataframe\n",
    "    out = pd.DataFrame(json[\"outstandingShares::quarterly\"]).T\n",
    "    out = out.drop([\"date\", \"sharesMln\"], axis = 1)[:6].rename(columns = {\"dateFormatted\":\"date\", \"shares\":\"outstandingShares\"})\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"]) #change dateformat to datetime\n",
    "    \n",
    "    #get earnings data and convert to dataframe\n",
    "    earn = pd.DataFrame(json[\"Earnings::History\"]).T\n",
    "    earn = earn.drop([\"reportDate\", \"beforeAfterMarket\"], axis = 1)[4:10].reset_index().drop(\"index\",axis = 1)\n",
    "    earn[\"date\"] = pd.to_datetime(earn[\"date\"]) #change dateformat to datetime\n",
    "\n",
    "    #merge both dataframes into one dataframe\n",
    "    fund = earn.merge(out, how = \"inner\", on = \"date\")\n",
    "    fund.set_index('date', inplace = True) #set date as index\n",
    "    fundamental = fund.resample('D').ffill() #resample dataset so it expands from quaterly to daily\n",
    "    fundamental.sort_index(ascending = False, inplace = True) #sort data to descending by date\n",
    "    fundamental.reset_index(inplace=True) #put date back as column - necessary for joining and merging later\n",
    "\n",
    "    fundamental = fundamental[(fundamental[\"date\"]<='2023-06-02') & (fundamental[\"date\"]>='2022-05-31')].reset_index()\n",
    "    \n",
    "    return fundamental\n",
    "\n",
    "\n",
    "def df_to_csv(df, name):\n",
    "    \"\"\"\n",
    "    Save a pandas dataframe into a csv file\n",
    "    \n",
    "    Args(pd.DataFrame, str): dataframe and the name of the file it should return.\n",
    "    When working with stock data name should be the ticker of the specified stock.\n",
    "    \n",
    "    requirements = requests, pandas, json should be installed and imported.\n",
    "    \n",
    "    returns 0, creates a csv file in /Data/Financial data\n",
    "    \"\"\"\n",
    "\n",
    "    pathname = Path.cwd()/f\"SingleStock_data/{name}.csv\"\n",
    "    \n",
    "    df.to_csv(pathname, index = False)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def log(ticker, df, logfile, output_path=os.getcwd()):\n",
    "    #open or create the csv file\n",
    "    if os.path.isfile(logfile): #if log file exist, open and allow changes\n",
    "        log = open(logfile,'a', enconding = \"utf-8\")\n",
    "    else:\n",
    "        log = open(logfile,'w')\n",
    "        header = ['timestamp', 'Status', 'length', 'output_file']\n",
    "        log.write(\";\".join(header)+\"\\n\") #Make the headers and jump to the new line\n",
    "    \n",
    "    #Gather log information\n",
    "    status_code = f\"last call made happened in ticker {ticker}\"\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())) #local time\n",
    "    length = len(df) #Lenght of HTML string\n",
    "    \n",
    "    #Open the log file and append the gathered log information\n",
    "    with open(logfile, 'a') as log:\n",
    "        log.write(f'{timestamp};{status_code};{length}' + \"\\n\") #Append the information and jump to the new line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe59160e-560e-4fce-acfc-9c86ccd3dc81",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d58f2e39-ddf0-43d1-8015-d19c07af0251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get list with all US-listed companies in NASDAQ exchange over 50m market cap\n",
    "cwd = Path.cwd() #current working directory\n",
    "nasdaq = pd.read_csv(\"Nasdaq mkt. cap 50m+.csv\")\n",
    "nasdaq = nasdaq.sort_values(\"Market Cap\", ascending = False).reset_index().drop(\"index\", axis = 1)\n",
    "tickers = nasdaq[\"Symbol\"].values\n",
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998a05fd-8e27-451f-ac6f-141fe46ea9c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [03:11,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company HBANM was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [06:52,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company PARAP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [08:12,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company AGNCL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "216it [10:54,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CHKEW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "226it [12:15,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CHKEZ was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244it [13:53,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CHKEL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "273it [15:53,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company ONBPO was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [16:57, 14.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company ONBPP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "289it [18:32,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CGABL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [23:25,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company OXLCN was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "397it [24:38,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company OXLCZ was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "470it [28:19,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company DHCNI was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "508it [30:41,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company RTLPO was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "522it [32:14,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company FULTP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "568it [35:07,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company FTAIN was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "571it [36:13, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company PACWP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "576it [37:24,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CSQ was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "669it [41:46,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company BPOPM was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "741it [45:17,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company FRMEP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "856it [50:44,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CDZIP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "872it [52:19,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company MBINM was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "882it [53:44,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company SIGIP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "891it [55:05,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company WAFDP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "895it [56:13,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company RWAYZ was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "898it [57:20, 13.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company RWAYL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "915it [58:59,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company MBINO was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "923it [1:00:18,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company TRINL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "928it [1:01:32,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company TCBIO was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "940it [1:03:01,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company HROWM was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "948it [1:04:21,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company FOSLL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "964it [1:05:57,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company LIFWZ was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "978it [1:07:30,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company RUMBW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "997it [1:09:27,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company MBINN was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "998it [1:10:30, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company GAINN was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1004it [1:11:43,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company HPKEW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1021it [1:13:23,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company RILYO was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1023it [1:14:27, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company GAINZ was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1056it [1:16:44,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company RILYK was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1068it [1:18:11,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company METCB was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1071it [1:19:17, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CNOBP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1079it [1:20:36,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company OPINL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1131it [1:23:35,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company SSSSL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1138it [1:24:52,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company GEGGL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1172it [1:27:12,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CHSCL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1198it [1:29:18,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company MSBIP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1224it [1:31:16,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company TBLD was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1230it [1:32:32,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company BWBBP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1236it [1:33:45,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CHSCM was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1243it [1:35:05,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company TFINP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1285it [1:37:50,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CHSCN was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1324it [1:40:18,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company THWWW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1341it [1:41:57,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company SEATW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1381it [1:44:23,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CCLDO was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1389it [1:45:40,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company GREEL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1395it [1:46:53,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company ATLCL was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1418it [1:48:57,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company EVLVW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1444it [1:50:57,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CHSCO was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1456it [1:52:28,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company OFSSH was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1491it [1:54:56,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company INDIW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1539it [1:57:43,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company WESTW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1614it [2:01:24,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company FGBIP was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1726it [2:06:42,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company AVPTW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1742it [2:08:19,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company SCLXW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1901it [2:15:25,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company SOUNW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1924it [2:17:14,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company LNZAW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1975it [2:20:09,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company EOSEW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2015it [2:22:40,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company CMPOW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2099it [2:26:51,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company ADVWW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2113it [2:28:21,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company GCMGW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2165it [2:31:19,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company MYPSW was not retrived from API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2188it [2:33:14,  4.20s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logfile = Path.cwd()/f'financial_data_logs.csv'\n",
    "missing = []\n",
    "index_missing = []\n",
    "\n",
    "for i, ticker in tqdm.tqdm(enumerate(tickers)):\n",
    "    try:\n",
    "        #Get End-of-Day stock price data\n",
    "        eod = stock_eod(ticker)\n",
    "        #Get fundamentals\n",
    "        fund = stock_fundamental(ticker)\n",
    "        \n",
    "        try:\n",
    "            eod.to_csv(cwd/f'Eod/{ticker}.csv', index = False)  #save end of day data only \n",
    "            fund.to_csv(cwd/f'Fundamentals/{ticker}.csv', index = False)  #save fundamental data only\n",
    "\n",
    "            #merge fundamental and end of day data on date\n",
    "            stock = eod.merge(fund, how = \"inner\", on = \"date\")\n",
    "            df_to_csv(stock,ticker) #save all data for the single stock\n",
    "            #log(ticker, stock, logfile) #track all succeded logs\n",
    "        except:\n",
    "            print(f\"Data for company {ticker} was retrieved from API but not saved\")\n",
    "                \n",
    "    except:\n",
    "        print(f'Company {ticker} was not retrived from API')\n",
    "        missing.append(ticker)\n",
    "        index_missing.append(i)\n",
    "        time.sleep(60)\n",
    "        \n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e67a16cb-5eec-4d75-9af8-183151b98d5f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'missing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m missing_values \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([missing, index_missing])\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mNameError\u001b[0m: name 'missing' is not defined"
     ]
    }
   ],
   "source": [
    "missing_values = pd.DataFrame([missing, index_missing]).T\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550c8c6-a6f2-4a4f-a6a4-ce45460e7523",
   "metadata": {},
   "source": [
    "### Validate datacollection\n",
    "As shown above there are 70 stocks that could not be retrieved. After some consideration it was decided to drop these stocks because of two reason.\n",
    "Some of them are just to small or were listed after 2023-06-01, meaning there will be some missing data.\n",
    "\n",
    "The last argument needs to be validated for all the stocks there is data on, as if some stocks have less available dates or na values then they should be reevaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "853e8dc3-2d66-4552-87ad-b87e21afb1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a validation log that saves the information of all stocks\n",
    "def log_val(ticker, df, logfile, output_path=os.getcwd()):\n",
    "    #open or create the csv file\n",
    "    if os.path.isfile(logfile): #if log file exist, open and allow changes\n",
    "        log = open(logfile,'a')\n",
    "    else:\n",
    "        log = open(logfile,'w')\n",
    "        header = ['Timestamp', 'Ticker', 'Shape', 'Accept', 'Nr. NaN values']\n",
    "        log.write(\";\".join(header)+\"\\n\") #Make the headers and jump to the new line\n",
    "    \n",
    "    accept = \"Yes\"\n",
    "    accept_cond = (254,14)\n",
    "    #Gather log information\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())) #local time\n",
    "    shape = df.shape\n",
    "    if df.shape != accept_cond:\n",
    "        accept = \"No\"\n",
    "    nan_val = sum(df.isna().sum().values)\n",
    "    \n",
    "    #Open the log file and append the gathered log information\n",
    "    with open(logfile, 'a') as log:\n",
    "        log.write(f'{timestamp};{ticker};{shape};{accept};{nan_val}' + \"\\n\") #Append the information and jump to the new line.\n",
    "        \n",
    "#create a validation log that saves the information of all stocks fundamentals\n",
    "def log_val_fund(ticker, df, logfile, output_path=os.getcwd()):\n",
    "    #open or create the csv file\n",
    "    if os.path.isfile(logfile): #if log file exist, open and allow changes\n",
    "        log = open(logfile,'a')\n",
    "    else:\n",
    "        log = open(logfile,'w')\n",
    "        header = ['Timestamp', 'Ticker', 'Shape', 'Accept', 'Nr. NaN values']\n",
    "        log.write(\";\".join(header)+\"\\n\") #Make the headers and jump to the new line\n",
    "    \n",
    "    accept = \"Yes\"\n",
    "    accept_cond = (368,8)\n",
    "    #Gather log information\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())) #local time\n",
    "    shape = df.shape\n",
    "    if df.shape != accept_cond:\n",
    "        accept = \"No\"\n",
    "    nan_val = sum(df.isna().sum().values)\n",
    "    \n",
    "    #Open the log file and append the gathered log information\n",
    "    with open(logfile, 'a') as log:\n",
    "        log.write(f'{timestamp};{ticker};{shape};{accept};{nan_val}' + \"\\n\") #Append the information and jump to the new line.\n",
    "\n",
    "#create a validation log that saves the information of all stocks eod\n",
    "def log_val_eod(ticker, df, logfile, output_path=os.getcwd()):\n",
    "    #open or create the csv file\n",
    "    if os.path.isfile(logfile): #if log file exist, open and allow changes\n",
    "        log = open(logfile,'a')\n",
    "    else:\n",
    "        log = open(logfile,'w')\n",
    "        header = ['Timestamp', 'Ticker', 'Shape', 'Accept', 'Nr. NaN values']\n",
    "        log.write(\";\".join(header)+\"\\n\") #Make the headers and jump to the new line\n",
    "    \n",
    "    accept = \"Yes\"\n",
    "    accept_cond = (254,7)\n",
    "    #Gather log information\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())) #local time\n",
    "    shape = df.shape\n",
    "    if df.shape != accept_cond:\n",
    "        accept = \"No\"\n",
    "    nan_val = sum(df.isna().sum().values)\n",
    "    \n",
    "    #Open the log file and append the gathered log information\n",
    "    with open(logfile, 'a') as log:\n",
    "        log.write(f'{timestamp};{ticker};{shape};{accept};{nan_val}' + \"\\n\") #Append the information and jump to the new line.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6ea071b3-302c-4e8e-a68b-7d6184fe9088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tickers #all tickers\n",
    "missing_values = pd.read_csv(\"missing_stocks.csv\")\n",
    "idxs = missing_values[\"1\"].values #index for missing companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe59a9-1e52-40c9-bac1-a788d7dd608f",
   "metadata": {},
   "source": [
    "#### Validation of Eod data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c9fb6079-29ec-47c1-b18b-b2425a88f903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The right shape for at stock is (254, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2188/2188 [00:18<00:00, 120.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#Get data for each stock and check it has the right shape. The right shape will be the same shape as apple stock has (has date on all cells)\n",
    "aapl = pd.read_csv(eod_path/\"AAPL.csv\")\n",
    "print(f\"The right shape for at stock is {aapl.shape}\")\n",
    "logval = Path.cwd()/f'Stock_validation_eod.csv'\n",
    "\n",
    "for i in tqdm.tqdm(range(len(tickers))):\n",
    "    #check if i stock is one of the 70 missing\n",
    "    abval = 0\n",
    "    for j in range(len(idxs)):\n",
    "        if i==0:\n",
    "            continue\n",
    "        elif i==idxs[j]:\n",
    "            abval = 1\n",
    "            #print(\"Missing company found with index: \",i)\n",
    "    if abval == 1:\n",
    "        continue\n",
    "    df = pd.read_csv(eod_path/f\"{tickers[i]}.csv\")\n",
    "    log_val_eod(tickers[i], df, logval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb1f1c-dc46-44c0-a654-56b828507133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1fcded9a-93df-46d9-a312-2eb9336ef346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get log-validation file created above\n",
    "validation_eod = pd.read_csv(\"Stock_validation_eod.csv\", sep = \";\")\n",
    "\n",
    "#Find all stocks that were not accepted due to data shortage\n",
    "eod_del = validation_eod[validation_eod[\"Accept\"]==\"No\"][\"Ticker\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d0a7e59c-a001-4efb-a5db-5d4cbd9c34a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2118/2118 [00:00<00:00, 53602.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2022"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we have 70 companies that could not be retrieved for API and 96 that were listed after the given date period.\n",
    "#Its time to remove these companies from the dataset\n",
    "\n",
    "#Remove Non-retrieved-data from tickers list:\n",
    "tickers_new = np.delete(tickers, idxs)\n",
    "\n",
    "#Remove tickers with incomple datasets from tickers_list\n",
    "index_eod_remove = []\n",
    "for i in tqdm.tqdm(range(len(tickers_new))):\n",
    "    for j in range(len(eod_del)):\n",
    "        if tickers_new[i] == eod_del[j]:\n",
    "            index_eod_remove.append(i)\n",
    "tickers_final = np.delete(tickers_new, index_eod_remove)\n",
    "len(tickers_final)\n",
    "\n",
    "#Save as csv file\n",
    "pd.DataFrame(tickers_final, columns = [\"Ticker\"]).to_csv(\"Tickers_final.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e3f64384-b27e-4ef4-a408-970d55ed3252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2118/2118 [00:00<00:00, 15272.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eod's removed:  96\n",
      "Fundamentals's removed:  96\n",
      "StockSingle's removed:  96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Now its time to remove \n",
    "\n",
    "eod_succed = []\n",
    "fundamentals_succed = []\n",
    "StockSingle_succed = []\n",
    "check = []\n",
    "\n",
    "#Delete all files from stocks with data less than one year\n",
    "for ticker in tqdm.tqdm(tickers_new):\n",
    "    for j in range(len(eod_del)):\n",
    "        if ticker==eod_del[j]:\n",
    "            check.append(ticker)\n",
    "            if os.path.exists(eod_path/f'{ticker}.csv'):\n",
    "                os.remove((eod_path/f'{ticker}.csv'))\n",
    "                eod_succed.append(1)\n",
    "            else:\n",
    "                eod_succed.append(0)\n",
    "\n",
    "            if os.path.exists(fundamentals_path/f'{ticker}.csv'):\n",
    "                os.remove((fundamentals_path/f'{ticker}.csv'))\n",
    "                fundamentals_succed.append(1)\n",
    "            else:\n",
    "                fundamentals_succed.append(0)\n",
    "\n",
    "            if os.path.exists(SingleStock_data/f'{ticker}.csv'):\n",
    "                os.remove((SingleStock_data/f'{ticker}.csv'))\n",
    "                StockSingle_succed.append(1)\n",
    "            else:\n",
    "                StockSingle_succed.append(0)\n",
    "\n",
    "print(\"Eod's removed: \",sum(eod_succed))\n",
    "print(\"Fundamentals's removed: \",sum(fundamentals_succed))\n",
    "print(\"StockSingle's removed: \",sum(StockSingle_succed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a886b39a-032c-4658-bbc3-43d2fbc65f52",
   "metadata": {},
   "source": [
    "#### Validation of fundamental data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9a8b972f-847b-4fca-89af-5f642a41788c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The right shape for at stock is (254, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2022/2022 [00:05<00:00, 341.27it/s]\n"
     ]
    }
   ],
   "source": [
    "aapl = pd.read_csv(eod_path/\"AAPL.csv\")\n",
    "print(f\"The right shape for at stock is {aapl.shape}\")\n",
    "logval = Path.cwd()/f'Stock_validation_fundamentals.csv'\n",
    "\n",
    "for i in tqdm.tqdm(range(len(tickers_final))):\n",
    "    #check if i stock is one of the 70 missing\n",
    "    df = pd.read_csv(fundamentals_path/f\"{tickers_final[i]}.csv\")\n",
    "    log_val_fund(tickers_final[i], df, logval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "abad1117-e588-422c-8622-a1fd23e98f44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)      285\n",
       "(305, 8)    141\n",
       "(123, 8)    138\n",
       "(215, 8)     24\n",
       "(31, 8)      15\n",
       "(338, 8)      3\n",
       "(64, 8)       2\n",
       "(246, 8)      2\n",
       "(185, 8)      1\n",
       "Name: Shape, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get log-validation file created above\n",
    "validation_fund = pd.read_csv(\"Stock_validation_fundamentals.csv\", sep = \";\")\n",
    "\n",
    "#Save a variable containing the tickers of datasets that were not accepted (Shape != (368,8))\n",
    "BadShape = validation_fund[validation_fund[\"Accept\"]==\"No\"]\n",
    "BadShape[\"Shape\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "929c37a9-625d-48ee-9186-b957d469ca28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Nr. NaN values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-16 15:03:26</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>(305, 8)</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-08-16 15:03:26</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>(0, 8)</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-08-16 15:03:26</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>(0, 8)</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-08-16 15:03:26</td>\n",
       "      <td>PEP</td>\n",
       "      <td>(305, 8)</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-08-16 15:03:26</td>\n",
       "      <td>COST</td>\n",
       "      <td>(0, 8)</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2023-08-16 15:03:31</td>\n",
       "      <td>VWE</td>\n",
       "      <td>(123, 8)</td>\n",
       "      <td>No</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2023-08-16 15:03:31</td>\n",
       "      <td>RCAT</td>\n",
       "      <td>(0, 8)</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2023-08-16 15:03:31</td>\n",
       "      <td>ESOA</td>\n",
       "      <td>(305, 8)</td>\n",
       "      <td>No</td>\n",
       "      <td>642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2023-08-16 15:03:31</td>\n",
       "      <td>CURI</td>\n",
       "      <td>(305, 8)</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2023-08-16 15:03:31</td>\n",
       "      <td>NSTS</td>\n",
       "      <td>(0, 8)</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>611 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp Ticker     Shape Accept  Nr. NaN values\n",
       "2     2023-08-16 15:03:26   GOOG  (305, 8)     No             0.0\n",
       "5     2023-08-16 15:03:26   NVDA    (0, 8)     No             0.0\n",
       "8     2023-08-16 15:03:26   AVGO    (0, 8)     No             0.0\n",
       "9     2023-08-16 15:03:26    PEP  (305, 8)     No             0.0\n",
       "10    2023-08-16 15:03:26   COST    (0, 8)     No             0.0\n",
       "...                   ...    ...       ...    ...             ...\n",
       "2015  2023-08-16 15:03:31    VWE  (123, 8)     No           123.0\n",
       "2016  2023-08-16 15:03:31   RCAT    (0, 8)     No             0.0\n",
       "2018  2023-08-16 15:03:31   ESOA  (305, 8)     No           642.0\n",
       "2019  2023-08-16 15:03:31   CURI  (305, 8)     No             0.0\n",
       "2020  2023-08-16 15:03:31   NSTS    (0, 8)     No             0.0\n",
       "\n",
       "[611 rows x 5 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BadShape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a3070-7920-483e-988e-707b9ab154da",
   "metadata": {},
   "source": [
    "### Get missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a4578-ffd7-47c5-88a4-43519675da9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
