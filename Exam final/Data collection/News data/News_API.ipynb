{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eodhd import APIClient\n",
    "import requests \n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "api = \"64d77f6d3a60a5.24835840\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log function\n",
    "def log_News(logfile,date,title,path=os.getcwd()):\n",
    "    # Open or create the csv file\n",
    "    if os.path.isfile(logfile): #If the log file exists, open it and allow for changes     \n",
    "        log = open(logfile,'a')\n",
    "    else: #If the log file does not exist, create it and make headers for the log variables\n",
    "        log = open(logfile,'w')\n",
    "        header = ['Timestamp','Date','Title']\n",
    "        log.write(';'.join(header) + \"\\n\") #Make the headers and jump to new line\n",
    "        \n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())) #Local time\n",
    "    \n",
    "    # Open the log file and append the gathered log information\n",
    "    with open(logfile,'a') as log:\n",
    "        log.write(f'{timestamp};{date};{title};{path}' + \"\\n\") #Append the information and jump to new line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the current working directory to the folder where the script is located\n",
    "os.chdir('C:/Users/Soren/Documents/GitHub/IntroSocial23/Exam final/Data collection')\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Construct the path to the CSV file\n",
    "csv_file_path = os.path.join(current_directory,'TickerNames_final.csv')\n",
    "\n",
    "# Read the CSV file and create a DataFrame\n",
    "df_companies = pd.read_csv(csv_file_path)\n",
    "\n",
    "# make df_companies into a dataframe\n",
    "df_companies = pd.DataFrame(df_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Symbol                                               Name\n",
      "0      AAPL                                          Apple Inc\n",
      "1      MSFT                 Microsoft Corporation Common Stock\n",
      "2      GOOG                                       Alphabet Inc\n",
      "3     GOOGL                                       Alphabet Inc\n",
      "4      AMZN                                             Amazon\n",
      "...     ...                                                ...\n",
      "2017   ICCH                                   ICC Holdings Inc\n",
      "2018   ESOA  Energy Services of America Corporation Common ...\n",
      "2019   CURI                                CuriosityStream Inc\n",
      "2020   NSTS                                   NSTS Bancorp Inc\n",
      "2021   STIM                                    Neuronetics Inc\n",
      "\n",
      "[2022 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching News:   0%|          | 0/2022 [00:00<?, ?stock/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching News: 100%|██████████| 2022/2022 [1:43:56<00:00,  3.08s/stock]  \n"
     ]
    }
   ],
   "source": [
    "# Get all news\n",
    "\n",
    "# Dates\n",
    "start_date = '2022-06-01'\n",
    "end_date = '2023-06-01'\n",
    "\n",
    "# number of articles pr. stock\n",
    "n_news = 1000\n",
    "# stock_list = ['AAPL','TSLA']\n",
    "stock_list = df_companies['Symbol']\n",
    "# company_names = ['Apple', 'Tesla']\n",
    "company_names = df_companies['Name']\n",
    "\n",
    "\n",
    "\n",
    "def get_all_news(stocks, start_date, end_date, n_news, api_key, company, offset = 0):\n",
    "    logfile = 'log_News.csv'\n",
    "\n",
    "    # create empty dataframe\n",
    "    all_news = pd.DataFrame()\n",
    "    for stock in tqdm(stocks, desc=\"Fetching News\", unit=\"stock\"):\n",
    "        # url for the api call\n",
    "        url = f'https://eodhistoricaldata.com/api/news?api_token={api_key}&s={stock}&limit={n_news}&offset={offset}&from={start_date}&to={end_date}'\n",
    "        # get the json from the api call\n",
    "        response = requests.get(url)\n",
    "        news_json = response.json()\n",
    "        \n",
    "        # create dataframe from json\n",
    "        df_news = pd.DataFrame.from_dict(news_json)\n",
    "        \n",
    "        # a new column with the company name \n",
    "        df_news['ticker'] = stock\n",
    "        df_news['company'] = company\n",
    "        \n",
    "        # concat df_news onto all_news\n",
    "        all_news = pd.concat([all_news, df_news], ignore_index = True)\n",
    "        \n",
    "        date = all_news['date']\n",
    "        title = all_news['title']        \n",
    "        \n",
    "        # Log the response\n",
    "        log_News(logfile, date, title)\n",
    "        \n",
    "        all_news = all_news[['date','title','symbols','sentiment','ticker','company']]\n",
    "        # save the dataframe\n",
    "        all_news.to_csv('df_all_news_final.csv', sep= ';', index=False)\n",
    "        \n",
    "    return all_news \n",
    "\n",
    "df_all_news_final = get_all_news(stock_list, start_date, end_date, n_news, api, company_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>symbols</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-01T22:45:24+00:00</td>\n",
       "      <td>Apple denies hacking thousands of iPhones in R...</td>\n",
       "      <td>[AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA]</td>\n",
       "      <td>{'polarity': 0.94, 'neg': 0.055, 'neu': 0.848,...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-01T22:02:25+00:00</td>\n",
       "      <td>Russia Accuses US Intelligence of Hacking Thou...</td>\n",
       "      <td>[AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA]</td>\n",
       "      <td>{'polarity': -0.942, 'neg': 0.091, 'neu': 0.83...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-01T21:43:00+00:00</td>\n",
       "      <td>Broadcom CEO Sees Rising AI Chip Demand. Earni...</td>\n",
       "      <td>[AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA...</td>\n",
       "      <td>{'polarity': 0.273, 'neg': 0, 'neu': 0.9, 'pos...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-01T20:55:29+00:00</td>\n",
       "      <td>Dow Jones Today: Debt Vote Drives Index Higher</td>\n",
       "      <td>[AAPL.MX, AAPL.US, AAPL34.SA, AEC1.F, AEC1.XET...</td>\n",
       "      <td>{'polarity': 0.572, 'neg': 0, 'neu': 0.893, 'p...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-01T20:24:46+00:00</td>\n",
       "      <td>Trillion-dollar companies: How wealthy are the...</td>\n",
       "      <td>[AAPL.MX, AAPL.US, AAPL34.SA, ABEA.F, ABEA.XET...</td>\n",
       "      <td>{'polarity': 0.44, 'neg': 0.061, 'neu': 0.847,...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180328</th>\n",
       "      <td>2022-07-13T12:31:00+00:00</td>\n",
       "      <td>Neuronetics Recognized as Top Non-Invasive Dev...</td>\n",
       "      <td>[STIM.US]</td>\n",
       "      <td>{'polarity': 0.929, 'neg': 0.079, 'neu': 0.795...</td>\n",
       "      <td>STIM</td>\n",
       "      <td>Neuronetics Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180329</th>\n",
       "      <td>2022-07-11T20:46:00+00:00</td>\n",
       "      <td>Neuronetics Announces Positive TMS Coverage Po...</td>\n",
       "      <td>[STIM.US]</td>\n",
       "      <td>{'polarity': 0.927, 'neg': 0.079, 'neu': 0.814...</td>\n",
       "      <td>STIM</td>\n",
       "      <td>Neuronetics Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180330</th>\n",
       "      <td>2022-06-27T18:55:25+00:00</td>\n",
       "      <td>Activist investor takes 13% stake in Malvern-b...</td>\n",
       "      <td>[NRC.F, STIM.US]</td>\n",
       "      <td>{'polarity': 0.527, 'neg': 0, 'neu': 0.947, 'p...</td>\n",
       "      <td>STIM</td>\n",
       "      <td>Neuronetics Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180331</th>\n",
       "      <td>2022-06-27T11:43:11+00:00</td>\n",
       "      <td>ClearPoint Neuro, Inc. (CLPT) Surges 7.6%: Is ...</td>\n",
       "      <td>[NRC.F, STIM.US]</td>\n",
       "      <td>{'polarity': 0.984, 'neg': 0.011, 'neu': 0.884...</td>\n",
       "      <td>STIM</td>\n",
       "      <td>Neuronetics Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180332</th>\n",
       "      <td>2022-06-24T18:48:00+00:00</td>\n",
       "      <td>Neuronetics, New Relic Stocks See Action From ...</td>\n",
       "      <td>[2NR.F, CRC.US, CRCQW.US, NEWR.US, NRC.F, S.US...</td>\n",
       "      <td>{'polarity': 0.402, 'neg': 0, 'neu': 0.881, 'p...</td>\n",
       "      <td>STIM</td>\n",
       "      <td>Neuronetics Inc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180333 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date  \\\n",
       "0       2023-06-01T22:45:24+00:00   \n",
       "1       2023-06-01T22:02:25+00:00   \n",
       "2       2023-06-01T21:43:00+00:00   \n",
       "3       2023-06-01T20:55:29+00:00   \n",
       "4       2023-06-01T20:24:46+00:00   \n",
       "...                           ...   \n",
       "180328  2022-07-13T12:31:00+00:00   \n",
       "180329  2022-07-11T20:46:00+00:00   \n",
       "180330  2022-06-27T18:55:25+00:00   \n",
       "180331  2022-06-27T11:43:11+00:00   \n",
       "180332  2022-06-24T18:48:00+00:00   \n",
       "\n",
       "                                                    title  \\\n",
       "0       Apple denies hacking thousands of iPhones in R...   \n",
       "1       Russia Accuses US Intelligence of Hacking Thou...   \n",
       "2       Broadcom CEO Sees Rising AI Chip Demand. Earni...   \n",
       "3          Dow Jones Today: Debt Vote Drives Index Higher   \n",
       "4       Trillion-dollar companies: How wealthy are the...   \n",
       "...                                                   ...   \n",
       "180328  Neuronetics Recognized as Top Non-Invasive Dev...   \n",
       "180329  Neuronetics Announces Positive TMS Coverage Po...   \n",
       "180330  Activist investor takes 13% stake in Malvern-b...   \n",
       "180331  ClearPoint Neuro, Inc. (CLPT) Surges 7.6%: Is ...   \n",
       "180332  Neuronetics, New Relic Stocks See Action From ...   \n",
       "\n",
       "                                                  symbols  \\\n",
       "0         [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA]   \n",
       "1         [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA]   \n",
       "2       [AAPL.MX, AAPL.US, AAPL34.SA, APC.F, APC.XETRA...   \n",
       "3       [AAPL.MX, AAPL.US, AAPL34.SA, AEC1.F, AEC1.XET...   \n",
       "4       [AAPL.MX, AAPL.US, AAPL34.SA, ABEA.F, ABEA.XET...   \n",
       "...                                                   ...   \n",
       "180328                                          [STIM.US]   \n",
       "180329                                          [STIM.US]   \n",
       "180330                                   [NRC.F, STIM.US]   \n",
       "180331                                   [NRC.F, STIM.US]   \n",
       "180332  [2NR.F, CRC.US, CRCQW.US, NEWR.US, NRC.F, S.US...   \n",
       "\n",
       "                                                sentiment ticker  \\\n",
       "0       {'polarity': 0.94, 'neg': 0.055, 'neu': 0.848,...   AAPL   \n",
       "1       {'polarity': -0.942, 'neg': 0.091, 'neu': 0.83...   AAPL   \n",
       "2       {'polarity': 0.273, 'neg': 0, 'neu': 0.9, 'pos...   AAPL   \n",
       "3       {'polarity': 0.572, 'neg': 0, 'neu': 0.893, 'p...   AAPL   \n",
       "4       {'polarity': 0.44, 'neg': 0.061, 'neu': 0.847,...   AAPL   \n",
       "...                                                   ...    ...   \n",
       "180328  {'polarity': 0.929, 'neg': 0.079, 'neu': 0.795...   STIM   \n",
       "180329  {'polarity': 0.927, 'neg': 0.079, 'neu': 0.814...   STIM   \n",
       "180330  {'polarity': 0.527, 'neg': 0, 'neu': 0.947, 'p...   STIM   \n",
       "180331  {'polarity': 0.984, 'neg': 0.011, 'neu': 0.884...   STIM   \n",
       "180332  {'polarity': 0.402, 'neg': 0, 'neu': 0.881, 'p...   STIM   \n",
       "\n",
       "                company  \n",
       "0             Apple Inc  \n",
       "1             Apple Inc  \n",
       "2             Apple Inc  \n",
       "3             Apple Inc  \n",
       "4             Apple Inc  \n",
       "...                 ...  \n",
       "180328  Neuronetics Inc  \n",
       "180329  Neuronetics Inc  \n",
       "180330  Neuronetics Inc  \n",
       "180331  Neuronetics Inc  \n",
       "180332  Neuronetics Inc  \n",
       "\n",
       "[180333 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the shape\n",
    "df_all_news_final.shape\n",
    "\n",
    "# copy of df_all_news_final\n",
    "df_all_news_copy = df_all_news_final.copy()\n",
    "\n",
    "# drop na's\n",
    "df_all_news_copy_na = df_all_news_copy.copy().dropna()\n",
    "\n",
    "# drop duplicates\n",
    "df_all_news_copy_duplicates = df_all_news_copy_na.drop_duplicates(subset=['date', 'title','ticker'], keep='first')\n",
    "\n",
    "# reset index\n",
    "df_all_news_duplicates = df_all_news_copy_duplicates.reset_index(drop=True)\n",
    "\n",
    "# remove the column company from the df_all_news_duplicates\n",
    "df_all_news_duplicates = df_all_news_duplicates.drop(columns=['company'])\n",
    "\n",
    "# Using list comprehension to match the tickers in df_all_news_duplicates with the symbol in df_companies and save the company name in a new column\n",
    "df_all_news_duplicates['company'] = [df_companies[df_companies['Symbol'] == ticker]['Name'].values[0] for ticker in df_all_news_duplicates['ticker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv with ; separator\n",
    "df_all_news_duplicates.to_csv('news_final_no_duplicates_3.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique titles\n",
    "# unique_tickers = df_all_news_duplicates['ticker'].unique()\n",
    "\n",
    "# # save unique titles as csv file\n",
    "# unique_tickers_df = pd.DataFrame(unique_tickers)\n",
    "# unique_tickers_df.to_csv('unique_tickers.csv', index=False)\n",
    "\n",
    "# open from csv the file news_final_no_duplicates_3.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tickers list for master dataframe\n",
    "tickers_list = df_all_news_final['ticker'].unique().tolist()\n",
    "tickers_list\n",
    "# Save tickers list as csv \n",
    "df_tickers_list = pd.DataFrame(tickers_list)\n",
    "df_tickers_list.to_csv('tickers_list_news.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df_all_news to csv\n",
    "df_all_news_final.to_csv('df_all_news_final_BACKUP.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date         object\n",
       "title        object\n",
       "symbols      object\n",
       "sentiment    object\n",
       "ticker       object\n",
       "company      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_news_copy.dtypes\n",
    "\n",
    "# change the columns title, ticker and company to string\n",
    "df_all_news_copy[['title','ticker','company']] = df_all_news_copy[['title','ticker','company']].astype(str)\n",
    "df_all_news_copy.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of title:  46.682490303078126\n"
     ]
    }
   ],
   "source": [
    "average_length_title = df_all_news_copy['title'].apply(len).mean()\n",
    "\n",
    "# average_length_article = df_all_news_final['content'].apply(len).mean()\n",
    "\n",
    "print('Average length of title: ', average_length_title)\n",
    "# print('Average length of article: ', average_length_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words in title:  7.321816404945886\n",
      "Average number of commas in title:  0.23402511791092792\n",
      "Average number of periods in title:  0.15606125905197793\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_all_news is your DataFrame\n",
    "# Calculate the average number of words, commas, and periods in the 'title' and 'content' columns\n",
    "df_all_news_copy['title_words'] = df_all_news_copy['title'].apply(lambda x: len(x.split()))\n",
    "df_all_news_copy['title_commas'] = df_all_news_copy['title'].apply(lambda x: x.count(','))\n",
    "df_all_news_copy['title_periods'] = df_all_news_copy['title'].apply(lambda x: x.count('.'))\n",
    "\n",
    "# df_all_news_final['content_words'] = df_all_news_final['content'].apply(lambda x: len(x.split()))\n",
    "# df_all_news_final['content_commas'] = df_all_news_final['content'].apply(lambda x: x.count(','))\n",
    "# df_all_news_final['content_periods'] = df_all_news_final['content'].apply(lambda x: x.count('.'))\n",
    "\n",
    "# Calculate the average values for words, commas, and periods in title and content\n",
    "average_words_title = df_all_news_copy['title_words'].mean()\n",
    "average_commas_title = df_all_news_copy['title_commas'].mean()\n",
    "average_periods_title = df_all_news_copy['title_periods'].mean()\n",
    "\n",
    "# average_words_content = df_all_news_final['content_words'].mean()\n",
    "# average_commas_content = df_all_news_final['content_commas'].mean()\n",
    "# average_periods_content = df_all_news_final['content_periods'].mean()\n",
    "\n",
    "# Print the results\n",
    "print('Average number of words in title: ', average_words_title)\n",
    "print('Average number of commas in title: ', average_commas_title)\n",
    "print('Average number of periods in title: ', average_periods_title)\n",
    "\n",
    "# print('Average number of words in content: ', average_words_content)\n",
    "# print('Average number of commas in content: ', average_commas_content)\n",
    "# print('Average number of periods in content: ', average_periods_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
